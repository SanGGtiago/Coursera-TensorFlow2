{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence modelling \n",
    "\n",
    "## Coding tutorials\n",
    " #### [1.  The IMDb dataset](#coding_tutorial_1)\n",
    " #### [2. Padding and masking sequence data](#coding_tutorial_2)\n",
    " #### [3. The Embedding layer](#coding_tutorial_3)\n",
    " #### [4. The Embedding Projector](#coding_tutorial_4)\n",
    " #### [5. Recurrent neural network layers](#coding_tutorial_5)\n",
    " #### [6. Stacked RNNs and the Bidirectional wrapper](#coding_tutorial_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## The IMDb Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import imdb\n",
    "\n",
    "import tensorflow.keras.datasets.imdb as imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Download and assign the data set using load_data()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) =imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the type of the data\n",
    "\n",
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the shape of the data\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 22665,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 21631,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 31050,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first dataset element input\n",
    "# Notice encoding\n",
    "\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first dataset element output\n",
    "\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset with different options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with defaults\n",
    "\n",
    "imdb.load_data(path='imdb.npz'\n",
    "              index_form=3)\n",
    "# ~/.keras/dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the vocabulary to the top 500 words using num_words\n",
    "\n",
    "imdb.load_data(num_words=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore the top 10 most frequent words using skip_top\n",
    "\n",
    "imdb.load_data(skip_top=10, num_words=1000, oov_char=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the sequence lengths to 500 using maxlen\n",
    "\n",
    "imdb.load_data(maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use '1' as the character that indicates the start of a sequence\n",
    "\n",
    "imdb.load_data(start_char=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imdb word index using get_word_index()\n",
    "\n",
    "imdb_word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the word index as a dictionary,\n",
    "# accounting for index_from.\n",
    "\n",
    "index_form = 3\n",
    "imdb_word_index = {key: value +index_form for key, value in imdb_word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52256 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(218, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve a specific word's index\n",
    "\n",
    "print(imdb_word_index['simpsonian'], imdb_word_index['the'])\n",
    "len(x_train[0]), index_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'film',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'casting',\n",
       " 'location',\n",
       " 'scenery',\n",
       " 'story',\n",
       " 'direction',\n",
       " \"everyone's\",\n",
       " 'really',\n",
       " 'suited',\n",
       " 'the',\n",
       " 'part',\n",
       " 'they',\n",
       " 'played',\n",
       " 'and',\n",
       " 'you',\n",
       " 'could',\n",
       " 'just',\n",
       " 'imagine',\n",
       " 'being',\n",
       " 'there',\n",
       " 'robert',\n",
       " \"redford's\",\n",
       " 'is',\n",
       " 'an',\n",
       " 'amazing',\n",
       " 'actor',\n",
       " 'and',\n",
       " 'now',\n",
       " 'the',\n",
       " 'same',\n",
       " 'being',\n",
       " 'director',\n",
       " \"norman's\",\n",
       " 'father',\n",
       " 'came',\n",
       " 'from',\n",
       " 'the',\n",
       " 'same',\n",
       " 'scottish',\n",
       " 'island',\n",
       " 'as',\n",
       " 'myself',\n",
       " 'so',\n",
       " 'i',\n",
       " 'loved',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'real',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'this',\n",
       " 'film',\n",
       " 'the',\n",
       " 'witty',\n",
       " 'remarks',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'film',\n",
       " 'were',\n",
       " 'great',\n",
       " 'it',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'so',\n",
       " 'much',\n",
       " 'that',\n",
       " 'i',\n",
       " 'bought',\n",
       " 'the',\n",
       " 'film',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'it',\n",
       " 'was',\n",
       " 'released',\n",
       " 'for',\n",
       " 'retail',\n",
       " 'and',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'it',\n",
       " 'to',\n",
       " 'everyone',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fly',\n",
       " 'fishing',\n",
       " 'was',\n",
       " 'amazing',\n",
       " 'really',\n",
       " 'cried',\n",
       " 'at',\n",
       " 'the',\n",
       " 'end',\n",
       " 'it',\n",
       " 'was',\n",
       " 'so',\n",
       " 'sad',\n",
       " 'and',\n",
       " 'you',\n",
       " 'know',\n",
       " 'what',\n",
       " 'they',\n",
       " 'say',\n",
       " 'if',\n",
       " 'you',\n",
       " 'cry',\n",
       " 'at',\n",
       " 'a',\n",
       " 'film',\n",
       " 'it',\n",
       " 'must',\n",
       " 'have',\n",
       " 'been',\n",
       " 'good',\n",
       " 'and',\n",
       " 'this',\n",
       " 'definitely',\n",
       " 'was',\n",
       " 'also',\n",
       " 'congratulations',\n",
       " 'to',\n",
       " 'the',\n",
       " 'two',\n",
       " 'little',\n",
       " \"boy's\",\n",
       " 'that',\n",
       " 'played',\n",
       " 'the',\n",
       " \"part's\",\n",
       " 'of',\n",
       " 'norman',\n",
       " 'and',\n",
       " 'paul',\n",
       " 'they',\n",
       " 'were',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'children',\n",
       " 'are',\n",
       " 'often',\n",
       " 'left',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'praising',\n",
       " 'list',\n",
       " 'i',\n",
       " 'think',\n",
       " 'because',\n",
       " 'the',\n",
       " 'stars',\n",
       " 'that',\n",
       " 'play',\n",
       " 'them',\n",
       " 'all',\n",
       " 'grown',\n",
       " 'up',\n",
       " 'are',\n",
       " 'such',\n",
       " 'a',\n",
       " 'big',\n",
       " 'profile',\n",
       " 'for',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'film',\n",
       " 'but',\n",
       " 'these',\n",
       " 'children',\n",
       " 'are',\n",
       " 'amazing',\n",
       " 'and',\n",
       " 'should',\n",
       " 'be',\n",
       " 'praised',\n",
       " 'for',\n",
       " 'what',\n",
       " 'they',\n",
       " 'have',\n",
       " 'done',\n",
       " \"don't\",\n",
       " 'you',\n",
       " 'think',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'story',\n",
       " 'was',\n",
       " 'so',\n",
       " 'lovely',\n",
       " 'because',\n",
       " 'it',\n",
       " 'was',\n",
       " 'true',\n",
       " 'and',\n",
       " 'was',\n",
       " \"someone's\",\n",
       " 'life',\n",
       " 'after',\n",
       " 'all',\n",
       " 'that',\n",
       " 'was',\n",
       " 'shared',\n",
       " 'with',\n",
       " 'us',\n",
       " 'all']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View an input sentence\n",
    "#它先取得index的key值,也就是'the'等等, 再從dataset裡抓每個key的index比the小的\n",
    "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}\n",
    "[inv_imdb_word_index[index] for index in x_train[0] if index > index_form]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the sentiment value\n",
    "\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Padding and Masking Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imdb data set\n",
    "\n",
    "import tensorflow.keras.datasets.imdb as imdb\n",
    "(x_train, y_train),(x_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the input data shape\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the inputs to the maximum length using maxlen\n",
    "\n",
    "padded_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=300, padding='post', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 300),\n",
       " array([    1,    14,    22,    16,    43,   530,   973,  1622,  1385,\n",
       "           65,   458,  4468,    66,  3941,     4,   173,    36,   256,\n",
       "            5,    25,   100,    43,   838,   112,    50,   670, 22665,\n",
       "            9,    35,   480,   284,     5,   150,     4,   172,   112,\n",
       "          167, 21631,   336,   385,    39,     4,   172,  4536,  1111,\n",
       "           17,   546,    38,    13,   447,     4,   192,    50,    16,\n",
       "            6,   147,  2025,    19,    14,    22,     4,  1920,  4613,\n",
       "          469,     4,    22,    71,    87,    12,    16,    43,   530,\n",
       "           38,    76,    15,    13,  1247,     4,    22,    17,   515,\n",
       "           17,    12,    16,   626,    18, 19193,     5,    62,   386,\n",
       "           12,     8,   316,     8,   106,     5,     4,  2223,  5244,\n",
       "           16,   480,    66,  3785,    33,     4,   130,    12,    16,\n",
       "           38,   619,     5,    25,   124,    51,    36,   135,    48,\n",
       "           25,  1415,    33,     6,    22,    12,   215,    28,    77,\n",
       "           52,     5,    14,   407,    16,    82, 10311,     8,     4,\n",
       "          107,   117,  5952,    15,   256,     4, 31050,     7,  3766,\n",
       "            5,   723,    36,    71,    43,   530,   476,    26,   400,\n",
       "          317,    46,     7,     4, 12118,  1029,    13,   104,    88,\n",
       "            4,   381,    15,   297,    98,    32,  2071,    56,    26,\n",
       "          141,     6,   194,  7486,    18,     4,   226,    22,    21,\n",
       "          134,   476,    26,   480,     5,   144,    30,  5535,    18,\n",
       "           51,    36,    28,   224,    92,    25,   104,     4,   226,\n",
       "           65,    16,    38,  1334,    88,    12,    16,   283,     5,\n",
       "           16,  4472,   113,   103,    32,    15,    16,  5345,    19,\n",
       "          178,    32,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0], dtype=int32))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the output data shape\n",
    "\n",
    "padded_x_train.shape, padded_x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Masking layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy \n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking expects to see (batch, sequence, features)\n",
    "# Create a dummy feature dimension using expand_dims\n",
    "\n",
    "padded_x_train = np.expand_dims(padded_x_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Masking layer \n",
    "\n",
    "tf_x_train = tf.convert_to_tensor(padded_x_train, dtype='float32')\n",
    "masking_layer = tf.keras.layers.Masking(mask_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass tf_x_train to it\n",
    "\n",
    "masked_x_train = masking_layer(tf_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=0, shape=(25000, 300, 1), dtype=float32, numpy=\n",
       "array([[[1.000e+00],\n",
       "        [1.400e+01],\n",
       "        [2.200e+01],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.940e+02],\n",
       "        [1.153e+03],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.400e+01],\n",
       "        [4.700e+01],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.100e+01],\n",
       "        [6.000e+00],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.446e+03],\n",
       "        [7.079e+03],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.700e+01],\n",
       "        [6.000e+00],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the dataset\n",
    "\n",
    "tf_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8, shape=(25000, 300), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False]])>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the ._keras_mask for the dataset\n",
    "\n",
    "masked_x_train._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## The Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and apply an `Embedding` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding layer using layers.Embedding\n",
    "# Specify input_dim, output_dim, input_length\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=501, output_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=24, shape=(1, 4, 1, 16), dtype=float32, numpy=\n",
       "array([[[[-0.00603823, -0.00872837, -0.01537516,  0.01691324,\n",
       "          -0.01813127,  0.01540865, -0.03214029, -0.038732  ,\n",
       "           0.01811428,  0.04956882,  0.00400442,  0.01457213,\n",
       "           0.01082819, -0.04819256, -0.03307819, -0.0070039 ]],\n",
       "\n",
       "        [[ 0.00612045,  0.02400985,  0.00865788,  0.02338869,\n",
       "          -0.01891493,  0.00613434, -0.04888427,  0.02852182,\n",
       "          -0.01741872, -0.01183723, -0.02204701,  0.04301602,\n",
       "           0.03706649,  0.03126993,  0.03943192, -0.0452759 ]],\n",
       "\n",
       "        [[ 0.04403559, -0.00730234,  0.00052723, -0.04818898,\n",
       "          -0.00168253, -0.03534492, -0.0472238 , -0.03073744,\n",
       "           0.00095321,  0.02762636,  0.03785909,  0.0269787 ,\n",
       "           0.01001754,  0.02602829, -0.02536464, -0.00125047]],\n",
       "\n",
       "        [[-0.04696513, -0.02619135, -0.04888917, -0.00753375,\n",
       "           0.04862568, -0.04988333,  0.03832276,  0.02016597,\n",
       "           0.0421516 ,  0.02818913, -0.03982013, -0.03290044,\n",
       "           0.02411468, -0.03715745, -0.03094682,  0.01288433]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect an Embedding layer output for a fixed input\n",
    "# Expects an input of shape (batch, sequence, feature)\n",
    "\n",
    "sequence_of_indices = tf.constant([[[0], [1], [5], [500]]])\n",
    "sequence_of_embeddings = embedding_layer(sequence_of_indices)\n",
    "sequence_of_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00603823, -0.00872837, -0.01537516, ..., -0.04819256,\n",
       "        -0.03307819, -0.0070039 ],\n",
       "       [ 0.00612045,  0.02400985,  0.00865788, ...,  0.03126993,\n",
       "         0.03943192, -0.0452759 ],\n",
       "       [-0.01787842,  0.01254174,  0.03512741, ..., -0.00323973,\n",
       "        -0.00731238, -0.00323236],\n",
       "       ...,\n",
       "       [-0.00382398, -0.04356369,  0.04811345, ..., -0.04312883,\n",
       "        -0.04041732, -0.02331456],\n",
       "       [ 0.03369956, -0.02946422,  0.00954254, ..., -0.04071472,\n",
       "        -0.0243718 ,  0.01530255],\n",
       "       [-0.04696513, -0.02619135, -0.04888917, ..., -0.03715745,\n",
       "        -0.03094682,  0.01288433]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Embedding layer weights using get_weights()\n",
    "\n",
    "embedding_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03861464,  0.03239841,  0.03175851,  0.04991269, -0.03485073,\n",
       "       -0.02108005,  0.00347707, -0.04086272,  0.0327337 ,  0.00646482,\n",
       "        0.04625983, -0.03281381,  0.02171943,  0.03431528, -0.02109195,\n",
       "       -0.00512606], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the embedding for the 14th index\n",
    "\n",
    "embedding_layer.get_weights()[0][14, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a layer that uses the mask_zero kwarg\n",
    "\n",
    "masking_embedding_layer = tf.keras.layers.Embedding(input_dim=501, output_dim=16, mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=42, shape=(1, 4, 1), dtype=bool, numpy=\n",
       "array([[[False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]]])>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply this layer to the sequence and see the _keras_mask property\n",
    "\n",
    "masked_sequence_of_embedding = masking_embedding_layer(sequence_of_indices)\n",
    "masked_sequence_of_embedding._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## The Embedding Projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess the IMDb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index\n",
    "\n",
    "imdb_word_index = get_imdb_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the keys and values of the word index\n",
    "\n",
    "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'david',\n",
       " 'lynch',\n",
       " 'and',\n",
       " 'have',\n",
       " 'everything',\n",
       " 'that',\n",
       " \"he's\",\n",
       " 'made',\n",
       " 'on',\n",
       " 'dvd',\n",
       " 'except',\n",
       " 'for',\n",
       " 'hotel',\n",
       " 'room',\n",
       " 'the',\n",
       " '2',\n",
       " 'hour',\n",
       " 'twin',\n",
       " 'peaks',\n",
       " 'movie',\n",
       " 'so',\n",
       " 'when',\n",
       " 'i',\n",
       " 'found',\n",
       " 'out',\n",
       " 'about',\n",
       " 'this',\n",
       " 'i',\n",
       " 'immediately',\n",
       " 'grabbed',\n",
       " 'it',\n",
       " 'and',\n",
       " 'and',\n",
       " 'what',\n",
       " 'is',\n",
       " 'this',\n",
       " \"it's\",\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'drawn',\n",
       " 'black',\n",
       " 'and',\n",
       " 'white',\n",
       " 'cartoons',\n",
       " 'that',\n",
       " 'are',\n",
       " 'loud',\n",
       " 'and',\n",
       " 'foul',\n",
       " 'mouthed',\n",
       " 'and',\n",
       " 'unfunny',\n",
       " 'maybe',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'know',\n",
       " \"what's\",\n",
       " 'good',\n",
       " 'but',\n",
       " 'maybe',\n",
       " 'this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'crap',\n",
       " 'that',\n",
       " 'was',\n",
       " 'on',\n",
       " 'the',\n",
       " 'public',\n",
       " 'under',\n",
       " 'the',\n",
       " 'name',\n",
       " 'of',\n",
       " 'david',\n",
       " 'lynch',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'few',\n",
       " 'bucks',\n",
       " 'too',\n",
       " 'let',\n",
       " 'me',\n",
       " 'make',\n",
       " 'it',\n",
       " 'clear',\n",
       " 'that',\n",
       " 'i',\n",
       " \"didn't\",\n",
       " 'care',\n",
       " 'about',\n",
       " 'the',\n",
       " 'foul',\n",
       " 'language',\n",
       " 'part',\n",
       " 'but',\n",
       " 'had',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'the',\n",
       " 'sound',\n",
       " 'because',\n",
       " 'my',\n",
       " 'neighbors',\n",
       " 'might',\n",
       " 'have',\n",
       " 'all',\n",
       " 'in',\n",
       " 'all',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'highly',\n",
       " 'disappointing',\n",
       " 'release',\n",
       " 'and',\n",
       " 'may',\n",
       " 'well',\n",
       " 'have',\n",
       " 'just',\n",
       " 'been',\n",
       " 'left',\n",
       " 'in',\n",
       " 'the',\n",
       " 'box',\n",
       " 'set',\n",
       " 'as',\n",
       " 'a',\n",
       " 'curiosity',\n",
       " 'i',\n",
       " 'highly',\n",
       " 'recommend',\n",
       " 'you',\n",
       " \"don't\",\n",
       " 'spend',\n",
       " 'your',\n",
       " 'money',\n",
       " 'on',\n",
       " 'this',\n",
       " '2',\n",
       " 'out',\n",
       " 'of',\n",
       " '10']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first dataset example sentence\n",
    "\n",
    "[inv_imdb_word_index[index] for index in x_train[100] if index > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build an Embedding layer into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum token value\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an embedding dimension\n",
    "\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using Sequential:\n",
    "#     1. Embedding layer\n",
    "#     2. GlobalAveragePooling1D\n",
    "#     3. Dense\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=False), \n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API refresher: use the Model to build the same model\n",
    "\n",
    "start = tf.keras.Input((None, ))\n",
    "em_seq = tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=False)(start)\n",
    "av_em = tf.keras.layers.GlobalAveragePooling1D()(em_seq)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(av_em)\n",
    "\n",
    "model = tf.keras.Model(inputs=start, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, None, 16)          160016    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,033\n",
      "Trainable params: 160,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile, train, and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with a binary cross-entropy loss\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    "    optimizer='adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.6893 - accuracy: 0.5669 - val_loss: 0.0174 - val_accuracy: 0.5453\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.6677 - accuracy: 0.6829 - val_loss: 0.0166 - val_accuracy: 0.7172\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.6253 - accuracy: 0.7553 - val_loss: 0.0153 - val_accuracy: 0.7703\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.5749 - accuracy: 0.7906 - val_loss: 0.0141 - val_accuracy: 0.7812\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.5272 - accuracy: 0.8192 - val_loss: 0.0130 - val_accuracy: 0.7969\n"
     ]
    }
   ],
   "source": [
    "# Train the model using .fit(), savng its history\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test), validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The TensorFlow embedding projector\n",
    "\n",
    "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the embedding layer's weights from the trained model\n",
    "\n",
    "weights = model.layers[1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/3/tutorials\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/vecs.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-45fbce89a16f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mout_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vecs.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mout_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'meta.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/vecs.tsv'"
     ]
    }
   ],
   "source": [
    "# Save the word Embeddings to tsv files\n",
    "# Two files: \n",
    "#     one contains the embedding labels (meta.tsv),\n",
    "#     one contains the embeddings (vecs.tsv)\n",
    "\n",
    "import io\n",
    "from os import path\n",
    "import os\n",
    "print(os.getcwd())\n",
    "out_v = io.open(path.join('data', 'vecs.tsv'), 'w', encoding='utf-8')\n",
    "out_m = io.open(path.join('data', 'meta.tsv'), 'w', encoding='utf-8')\n",
    "\n",
    "k = 0\n",
    "\n",
    "for word, token in word_index.items():\n",
    "    if k != 0:\n",
    "        out_m.write('\\n')\n",
    "        out_v.write('\\n')\n",
    "    \n",
    "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
    "    out_m.write(word)\n",
    "    k += 1\n",
    "    \n",
    "out_v.close()\n",
    "out_m.close()\n",
    "# beware large collections of embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## Recurrent neural network layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize and pass an input to a SimpleRNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SimpleRNN layer and test it\n",
    "\n",
    "simplermm_layer = tf.keras.layers.SimpleRNN(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=13384, shape=(1, 16), dtype=float32, numpy=\n",
       "array([[ 0.4715775 ,  0.9167975 , -0.96738577,  0.6617303 ,  0.11051562,\n",
       "         0.8111362 ,  0.74418014, -0.75428593,  0.99029565,  0.7433237 ,\n",
       "        -0.57945585,  0.00607975, -0.84859496, -0.97033787,  0.97759694,\n",
       "         0.96718395]], dtype=float32)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that only the final cell output is returned\n",
    "\n",
    "sequence = tf.constant([[[1., 1.], [2., 2.], [3., 3.]]])\n",
    "layer_output = simplermm_layer(sequence)\n",
    "layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and transform the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = get_and_pad_imdb_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "\n",
    "word_index = get_imdb_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a recurrent neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum index value\n",
    "\n",
    "max_index_value = max(word_index.values())\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build the model:\n",
    "# 1. Embedding.\n",
    "# 2. LSTM.\n",
    "# 3. Dense.\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.LSTM(16),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with binary cross-entropy loss\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "Epoch 1/3\n",
      "18848/25000 [=====================>........] - ETA: 24:36 - loss: 0.4566 - accuracy: 0.7849"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-662d1b79e50d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the model and save its training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the model and save its training history\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);\n",
    "\n",
    "#### Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['please',\n",
       " 'give',\n",
       " 'this',\n",
       " 'one',\n",
       " 'a',\n",
       " 'miss',\n",
       " 'br',\n",
       " 'br',\n",
       " 'and',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cast',\n",
       " 'rendered',\n",
       " 'terrible',\n",
       " 'performances',\n",
       " 'the',\n",
       " 'show',\n",
       " 'is',\n",
       " 'flat',\n",
       " 'flat',\n",
       " 'flat',\n",
       " 'br',\n",
       " 'br',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'know',\n",
       " 'how',\n",
       " 'michael',\n",
       " 'madison',\n",
       " 'could',\n",
       " 'have',\n",
       " 'allowed',\n",
       " 'this',\n",
       " 'one',\n",
       " 'on',\n",
       " 'his',\n",
       " 'plate',\n",
       " 'he',\n",
       " 'almost',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'know',\n",
       " 'this',\n",
       " \"wasn't\",\n",
       " 'going',\n",
       " 'to',\n",
       " 'work',\n",
       " 'out',\n",
       " 'and',\n",
       " 'his',\n",
       " 'performance',\n",
       " 'was',\n",
       " 'quite',\n",
       " 'so',\n",
       " 'all',\n",
       " 'you',\n",
       " 'madison',\n",
       " 'fans',\n",
       " 'give',\n",
       " 'this',\n",
       " 'a',\n",
       " 'miss']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first test data example sentence\n",
    "# (invert the word index)\n",
    "inv_imdb_word_index = {value:key for key, value in word_index.items()}\n",
    "[inv_imdb_word_index[index]for index in x_test[0] if index > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model prediction using model.predict()\n",
    "\n",
    "model.predict(x_test[None, o, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the corresponding label\n",
    "\n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_6\"></a>\n",
    "## Stacked RNNs and the Bidirectional wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and transform the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test)= get_and_pad_imdb_dataset(num_words=5000, maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "\n",
    "word_index = get_imdb_word_index(num_words=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build stacked and bidirectional recurrent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum index value and specify an embedding dimension\n",
    "\n",
    "max_index_value = max(word_index.values())\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim = embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim = embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(layer = tf.keras.layers.LSTM(8), merge_mode='sum', backward_layer=tf.keras.layers.GRU(8, go_backwards=True)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(layer = tf.keras.layers.LSTM(8, return_sequences=True), merge_mode='concat'),\n",
    "    tf.keras.layers.GRU(8, return_sequences=False),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 974s 39ms/sample - loss: 0.3985 - accuracy: 0.8142\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 849s 34ms/sample - loss: 0.2516 - accuracy: 0.9024\n",
      "Epoch 3/3\n",
      "19968/25000 [======================>.......] - ETA: 3:00 - loss: 0.1940 - accuracy: 0.9277"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-4e41dc00616f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model, saving its history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model, saving its history\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
